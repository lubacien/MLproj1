{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from cross_validation import *\n",
    "from data_preprocessing import *\n",
    "from proj1_helpers import *\n",
    "import math\n",
    "\n",
    "print('loading data'+\"\\n\")\n",
    "DATA_TEST_PATH = '../data/train.csv'\n",
    "y,tX,ids = load_csv_data(DATA_TEST_PATH)\n",
    "print('data loaded')\n",
    "\n",
    "jet_set = jet(tX)\n",
    "inds = create_inds(jet_set, False)\n",
    "\n",
    "data_sets = jet_split(tX,inds)\n",
    "y_sets = split_y(y,inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    ''' fill your code in here...\n",
    "    '''\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    \n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, tX, lambda_, degree, ratio):\n",
    "    \n",
    "    for i in range(int(1/(1-ratio))):\n",
    "\n",
    "        xtrain, ytrain, xtest, ytest = split_data(tX, y, ratio)\n",
    "        \n",
    "        xtrain_std = standardize(xtrain)\n",
    "        xtest_std = standardize(xtest)\n",
    "        \n",
    "        weights_ = []\n",
    "        trainlosses = []\n",
    "        testlosses = []\n",
    "\n",
    "        data_set=build_poly(xtrain_std,degree)\n",
    "        data_set_test=build_poly(xtest_std,degree)\n",
    "\n",
    "        w, loss = ridge_regression(ytrain,data_set,lambda_)\n",
    "\n",
    "        weights_.append(w)\n",
    "        trainlosses.append(loss)\n",
    "        testlosses.append(compute_loss(ytest,data_set_test,w))\n",
    "            \n",
    "    #print(\"test error =\",np.mean(testlosses))\n",
    "    #print(\"train error =\", np.mean(trainlosses))\n",
    "\n",
    "    return np.mean(testlosses), np.mean(trainlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1, 1, 1, 1, 1]]\n",
    "weights_ = []\n",
    "losses = []\n",
    "lambda_= [1]\n",
    "degree = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "for lam in lambda_:\n",
    "    for deg in degree:\n",
    "        for data_set, y_set in zip(data_sets, y_sets):\n",
    "            test_error, train_error = cross_validation(y_set, data_set, lam, deg, 0.8)\n",
    "            losses.append(test_error)\n",
    "            #losses.append(train_error)\n",
    "            \n",
    "        matrix = np.append(matrix, [[lam, deg, losses[0], losses[1], losses[2]]], axis = 0)\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 3.80021528e-01, 4.58167523e-01,\n",
       "        4.93653115e-01],\n",
       "       [1.00000000e+00, 1.00000000e+00, 4.42426600e-01, 4.79451030e-01,\n",
       "        4.97660294e-01],\n",
       "       [1.00000000e+00, 2.00000000e+00, 4.21974784e-01, 4.75604057e-01,\n",
       "        4.97063953e-01],\n",
       "       [1.00000000e+00, 3.00000000e+00, 4.32459896e-01, 4.81061742e-01,\n",
       "        4.96269953e-01],\n",
       "       [1.00000000e+00, 4.00000000e+00, 1.09149910e+03, 4.80725448e-01,\n",
       "        5.02901061e-01],\n",
       "       [1.00000000e+00, 5.00000000e+00, 6.10637978e+07, 4.88922717e-01,\n",
       "        5.00530948e-01],\n",
       "       [1.00000000e+00, 6.00000000e+00, 2.17707277e+09, 5.07978063e-01,\n",
       "        5.23375538e-01],\n",
       "       [1.00000000e+00, 7.00000000e+00, 2.58117694e+05, 5.02166891e-01,\n",
       "        5.90350435e-01],\n",
       "       [1.00000000e+00, 8.00000000e+00, 5.17821726e-01, 5.10805105e-01,\n",
       "        1.63462442e+00],\n",
       "       [1.00000000e+00, 9.00000000e+00, 2.47953469e+00, 1.01161018e+00,\n",
       "        5.62559349e+00],\n",
       "       [1.00000000e+00, 1.00000000e+01, 1.09856962e+03, 8.36558997e+00,\n",
       "        2.65129157e+01],\n",
       "       [1.00000000e+00, 1.10000000e+01, 4.29142367e+09, 5.32858243e+00,\n",
       "        9.55378460e+01],\n",
       "       [1.00000000e+00, 1.20000000e+01, 6.02032259e+04, 4.83998986e+01,\n",
       "        8.08511404e+02]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.38002153, 0.45816752, 0.49365312])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minInColumns = np.amin(matrix, axis=0)\n",
    "minInColumns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
