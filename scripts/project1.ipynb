{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from cross_validation import *\n",
    "from data_preprocessing import *\n",
    "from proj1_helpers import *\n",
    "from costs import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data\n",
      "\n",
      "training data loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('loading training data'+\"\\n\")\n",
    "DATA_TEST_PATH = '../data/train.csv'\n",
    "y,tX,ids = load_csv_data(DATA_TEST_PATH)\n",
    "print('training data loaded'+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares Gradient Descent implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0\n",
      "test error: 0.499935094242\n",
      "train error: 0.49993572488\n",
      "accuracy: 0.784395956361\n",
      "Subset: 1\n",
      "test error: 0.499960251879\n",
      "train error: 0.49996061264\n",
      "accuracy: 0.694931648182\n",
      "Subset: 2\n",
      "test error: 0.499936268265\n",
      "train error: 0.499936855991\n",
      "accuracy: 0.694871794872\n"
     ]
    }
   ],
   "source": [
    "jet_tX = jet(tX)\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degree = [1, 1, 1]\n",
    "# cleans -999 and standardizes\n",
    "for i in range(len(jet_tX)):\n",
    "    print(\"Subset: \" + str(i))\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    acc, testloss, trainloss, weights = cross_validation_for_GD(y[jet_tX[i]], preprocessed_tX, degree[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares Stochastic Gradient Descent implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0\n",
      "test error: 0.499954534955\n",
      "train error: 0.499891886642\n",
      "accuracy: 0.731208087279\n",
      "Subset: 1\n",
      "test error: 0.499975946183\n",
      "train error: 0.499979199915\n",
      "accuracy: 0.67010575187\n",
      "Subset: 2\n",
      "test error: 0.499947153216\n",
      "train error: 0.4998881644\n",
      "accuracy: 0.681816928591\n"
     ]
    }
   ],
   "source": [
    "jet_tX = jet(tX)\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degree = [1, 1, 1]\n",
    "# cleans -999 and standardizes\n",
    "for i in range(len(jet_tX)):\n",
    "    print(\"Subset: \" + str(i))\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    acc, testloss, trainloss, weights = cross_validation_for_GD(y[jet_tX[i]], preprocessed_tX, degree[i], stoch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset: 0\n",
      "test error: 34179422.732\n",
      "train error: 0.241024145617\n",
      "accuracy: 0.832529276349\n",
      "subset: 1\n",
      "test error: 0.334557967773\n",
      "train error: 0.322174455215\n",
      "accuracy: 0.775973690998\n",
      "subset: 2\n",
      "test error: 93691.61798\n",
      "train error: 0.328329868807\n",
      "accuracy: 0.782271850014\n"
     ]
    }
   ],
   "source": [
    "jet_tX = jet(tX)\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degrees = [4,4,11]\n",
    "# cleans -999 and standardizes\n",
    "for i in range(len(jet_tX)):\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    print(\"subset: \" + str(i))\n",
    "\n",
    "    acc, testloss, trainloss, weights = cross_validation_for_leastsquares(y[jet_tX[i]], preprocessed_tX, degrees[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0\n",
      "test error: 6.42360649512e+38\n",
      "train error: 0.230647760947\n",
      "accuracy: 0.84288859974\n",
      "Subset: 1\n",
      "test error: 56838.9501348\n",
      "train error: 0.287514196408\n",
      "accuracy: 0.804526695899\n",
      "Subset: 2\n",
      "test error: 9114959.92082\n",
      "train error: 0.260537970987\n",
      "accuracy: 0.829432037497\n"
     ]
    }
   ],
   "source": [
    "jet_tX = jet(tX)\n",
    "\n",
    "lams= [1e-4,0.001,1e-5]\n",
    "\n",
    "degs = 12*np.ones(3).astype(int)\n",
    "losses=[]\n",
    "\n",
    "for i in range(len(jet_tX)):\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    print(\"Subset: \" + str(i))\n",
    "    acc, testloss, trainloss, weights = cross_validation_ridge(y[jet_tX[i]], preprocessed_tX,lams[i],degs[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0\n",
      "test error: 0.607156524739\n",
      "train error: 35868.3143443\n",
      "accuracy: 0.814272845561\n",
      "Subset: 1\n",
      "test error: 0.491508456431\n",
      "train error: 35341.3732367\n",
      "accuracy: 0.705751870003\n",
      "Subset: 2\n",
      "test error: 0.55110153738\n",
      "train error: 32326.4341239\n",
      "accuracy: 0.709925558313\n"
     ]
    }
   ],
   "source": [
    "jet_tX = jet(tX)\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degree = [1, 1, 1]\n",
    "# cleans -999 and standardizes\n",
    "for i in range(len(jet_tX)):\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    print(\"Subset: \" + str(i))\n",
    "    acc, testloss, trainloss, weights = cross_validation_for_logistic(y[jet_tX[i]], preprocessed_tX, degree[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularised logistic regression implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a Grid Search for the best lambdas of each independent models using regularised logistic regression. The next cell takes a few minutes to run, but the results have already been added in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 1.0\n",
      "lambda= 1.43844988829\n",
      "lambda= 2.06913808111\n",
      "lambda= 2.97635144163\n",
      "lambda= 4.28133239872\n",
      "lambda= 6.15848211066\n",
      "lambda= 8.8586679041\n",
      "lambda= 12.742749857\n",
      "lambda= 18.3298071083\n",
      "lambda= 26.3665089873\n",
      "lambda= 37.9269019073\n",
      "lambda= 54.5559478117\n",
      "lambda= 78.4759970351\n",
      "lambda= 112.883789168\n",
      "lambda= 162.377673919\n",
      "lambda= 233.572146909\n",
      "lambda= 335.981828628\n",
      "lambda= 483.293023857\n",
      "lambda= 695.192796178\n",
      "lambda= 1000.0\n",
      "0.687425844725\n"
     ]
    }
   ],
   "source": [
    "#grid search for best lambdas\n",
    "jet_tX = jet(tX)\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degree = [1,1,1]\n",
    "# cleans -999 and standardizes\n",
    "accs=[]\n",
    "lambdas=np.logspace(0,3,num=20)\n",
    "for lambda_ in lambdas:\n",
    "    print(\"lambda=\",lambda_)\n",
    "    for i in range(len(jet_tX)):\n",
    "        # preprocess every train subset\n",
    "        preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "        acc, testloss, trainloss, weights = cross_validation_for_reglogistic(y[jet_tX[i]], preprocessed_tX,lambda_, degree[i])\n",
    "        accs.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the lambdas corresponding to the minimum values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233.57214690901213, 2.9763514416313179, 78.475997035146108]\n"
     ]
    }
   ],
   "source": [
    "accsme=accs.reshape(-1,3)\n",
    "goodlambdas=[lambdas[np.argmax(accsme[:,0])], lambdas[np.argmax(accsme[:,1])], lambdas[np.argmax(accsme[:,2])]]\n",
    "print(goodlambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0\n",
      "test error: 0.643346313135\n",
      "train error: 36149.1896223\n",
      "accuracy: 0.815273746372\n",
      "Subset: 1\n",
      "test error: 0.491512282785\n",
      "train error: 35342.9228542\n",
      "accuracy: 0.705738973433\n",
      "Subset: 2\n",
      "test error: 0.551191449409\n",
      "train error: 32381.4164391\n",
      "accuracy: 0.710669975186\n"
     ]
    }
   ],
   "source": [
    "#function called with the bestlambdas found in previous step\n",
    "jet_tX = jet(tX)\n",
    "\n",
    "goodlambdas= [233.57214690901213, 2.9763514416313179, 78.475997035146108]\n",
    "\n",
    "means = []\n",
    "devs = []\n",
    "degree = [1,1,1]\n",
    "# cleans -999 and standardizes\n",
    "accs=[]\n",
    "\n",
    "lambdas=goodlambdas\n",
    "\n",
    "for i in range(len(jet_tX)):\n",
    "    print(\"Subset: \" + str(i))\n",
    "    # preprocess every train subset\n",
    "    preprocessed_tX = preprocess_data(tX[jet_tX[i]])\n",
    "    acc, testloss, trainloss, weights = cross_validation_for_reglogistic(y[jet_tX[i]], preprocessed_tX,lambdas[i], degree[i])\n",
    "    print(\"test error:\", testloss)\n",
    "    print(\"train error:\", trainloss)\n",
    "    print(\"accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission_splitt.csv'\n",
    "create_csv_submission(ids_test, y_preds, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#polynomial expansion of test data\n",
    "#tX_testpol=build_poly(tX_test,degree)\n",
    "\n",
    "OUTPUT_PATH = '../data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
